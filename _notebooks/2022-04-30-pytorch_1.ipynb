{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial - Part 1\n",
    "> \"Part 1 of the PyTorch tutorial -- I'm transitioning from TF to PyTorch and I'm starting from the complete basics here.\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Scott Wolf\n",
    "- categories: [PyTorch, jupyter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFS82fhgA-YU"
   },
   "source": [
    "# Tensors!\n",
    "\n",
    "As I transition from TensorFlow and Keras to PyTorch, I am going back through the basic docs of PyTorch and this series of posts will document that. Nearly all of this is directly from the PyTorch tutorials but rewriting and commenting will hopefully help me learn and possibly help others make the TF -> PyTorch transition cleaner!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI3kU5OMBepR"
   },
   "source": [
    "Building tensors! Just like with most deep learning frameworks, PyTorch uses tensors to encode the inputs and outputs of models along with the model parameters. The main difference between the n-dimensional arrays of NumPy (ndarrays) is that they're compatible with hardware accelerators and optimized for automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3385,
     "status": "ok",
     "timestamp": 1651348900570,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "Dibf0Xl7_lNr"
   },
   "outputs": [],
   "source": [
    "# Building tensors\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1651348900570,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "TZCBkXxBB494",
    "outputId": "53303de6-b6bb-4619-ed50-f4512472117b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random tensor: \n",
      " tensor([[0.3120, 0.7831],\n",
      "        [0.9336, 0.7780]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets build directly from data!\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "data_tensor = torch.tensor(data)\n",
    "\n",
    "# This also works from numpy arrays!\n",
    "data_np = np.array(data)\n",
    "data_tensor_from_np = torch.from_numpy(data_np)\n",
    "\n",
    "# Or even from another tensor!\n",
    "\n",
    "ones_tensor = torch.ones_like(data_tensor)\n",
    "print(f\"Ones tensor: \\n {ones_tensor} \\n\")\n",
    "\n",
    "rand_tensor = torch.rand_like(data_tensor, dtype=torch.float)  # dtype required!\n",
    "print(f\"Random tensor: \\n {rand_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651348900571,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "vIB1EaShCJwG",
    "outputId": "e320c905-ad2c-4c01-9f2d-4cf4e7e63996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.0923, 0.6174, 0.4717],\n",
      "        [0.7022, 0.7585, 0.7783]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Or as above with just a shape!\n",
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651348900571,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "JjEXOJ6VC5is",
    "outputId": "825d05c2-924f-4ebc-cd76-d1dbb8b324a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([2, 3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor: {rand_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {rand_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {rand_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPUcSQl3DOCM"
   },
   "source": [
    "## Operations\n",
    "\n",
    "Now lets quickly move into operations on tensors. Because we're working on Colab, we're gonna go ahead and move it to the GPU for speed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1651348984135,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "2_f_quQhDK0v",
    "outputId": "dc257c02-5a8b-4969-f14f-2fc6f4150f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available -- moving the tensor to the GPU!\n"
     ]
    }
   ],
   "source": [
    "# Make sure cuda is available and, if so, move the tensor.\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda is available -- moving the tensor to the GPU!\")\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1651349100638,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "3WhrY1_NETvG",
    "outputId": "0b3afaa3-3056-4b8a-a2e1-428f91512fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Just like numpy!\n",
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651349174998,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "WblV8vzpEsj_",
    "outputId": "1452f5a2-354b-4fd0-abf7-5b14c5fba8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# We can concatenate them just like normal arrays\n",
    "# Here we're just appending along dim 1 (cols)\n",
    "\n",
    "print(torch.cat([tensor, tensor, tensor], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EJjOJYvFXKQ"
   },
   "source": [
    "Now onto some actual computations. Lets start with some basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1651349501230,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "6_GyMHTUFInr",
    "outputId": "1d49e4a5-a1fa-4b48-ed5a-6546889bccd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y1, y2, and y3 are equivalent.\n",
    "# Note that for y3, we're just filling a preallocated tensor with the product.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651349502647,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "KuFI7N9pFwCj",
    "outputId": "562be1e5-b326-4fbb-9082-7892b9027a89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can directly extend this to element-wise product as well\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651349632337,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "1jWg0JdTGYol",
    "outputId": "144845ec-7897-40ff-8dd1-3a8ebbbfb6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Now some aggregate metrics -- note we can use .item() to get back to a python numerical.\n",
    "sum = tensor.sum()\n",
    "print(sum.item(), type(sum.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1651349723665,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "HxLyth3vGcVR",
    "outputId": "7954461a-5622-405e-f5fe-0e4eb57d2a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]]) \n",
      "\n",
      "tensor([[11., 10., 11., 11.],\n",
      "        [11., 10., 11., 11.],\n",
      "        [11., 10., 11., 11.],\n",
      "        [11., 10., 11., 11.]])\n"
     ]
    }
   ],
   "source": [
    "# In-place operations!\n",
    "\n",
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)  # Just leave off the _ to stop this from being in-place!\n",
    "print(f\"{tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN2uVDG9Hajn"
   },
   "source": [
    "## NumPy bridging!\n",
    "We can share the underlying memory between tensors and numpy arrays when on the cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1651349887060,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "S5lwXf58HvLz",
    "outputId": "f05bf5b2-b12d-4ee1-bf68-b14cbeb804fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([  1.,   1., 123.,   1.,   1.])\n",
      "n: [  1.   1. 123.   1.   1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "t[2] = 123\n",
    "\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1651349975460,
     "user": {
      "displayName": "Scott Wolf",
      "userId": "03447010338150970414"
     },
     "user_tz": 240
    },
    "id": "CdvIQUtyH2_O",
    "outputId": "45423b97-2b7c-4852-f214-74c78e30322a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "n: [  1.   1. 123.   1.   1.]\n",
      "t: tensor([  1.,   1., 123.,   1.,   1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# from numpy does this too!\n",
    "\n",
    "n = np.ones(5)\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"t: {t}\")\n",
    "\n",
    "\n",
    "n[2] = 123\n",
    "\n",
    "print(f\"n: {n}\")\n",
    "print(f\"t: {t}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM5H6qSdGACj4+M7ZP3kGlT",
   "collapsed_sections": [],
   "name": "pytorch_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
